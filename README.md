# Sentiment-Analysis-with-Deep-Learning-using-BERT
The code analyzes a dataset for sentiment analysis using PyTorch BERT model for multi-class classification

We will analyze a dataset for sentiment analysis. Then read in a PyTorch BERT model, and adjust the architecture for multi-class classification. 
We will adjust an optimizer and scheduler for ideal training and performance. In finetuning this model, we will design a train and evaluate loop 
to monitor model performance as it trains, including saving and loading models. 

Finally, we will build a Sentiment Analysis model that leverages BERT's large-scale language knowledge.

<B>Learning Objectives</B>

What BERT is and what it can do

Clean and preprocess text dataset

Split dataset into training and validation sets using stratified approach

Tokenize (encode) dataset using BERT toknizer

Design BERT finetuning architecture

Evaluate performance using F1 scores and accuracy

Finetune BERT using training loop

